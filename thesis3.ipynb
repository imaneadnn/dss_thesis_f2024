{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target encoding the preprocessed df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset: (141447, 46)\n"
     ]
    }
   ],
   "source": [
    "# loading preprocessed dataset (before encoding)\n",
    "\n",
    "df = pd.read_csv(\"pp_no_encoding.csv\")\n",
    "target = 'seller_pass_rate'\n",
    "print(\"Loaded dataset:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Add target back to X_train for encoding purposes only\n",
    "X_train[target] = y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create mapping from the original notebook\n",
    "# seller_country_mapping = X_train[['seller_country', 'seller_pass_rate']].groupby('seller_country')['seller_pass_rate'].mean()\n",
    "# seller_country_mapping = seller_country_mapping.reset_index()\n",
    "# seller_country_mapping.columns = ['seller_country', 'seller_country_target_enc']\n",
    "\n",
    "# # Save the mapping to a CSV file\n",
    "# seller_country_mapping.to_csv('seller_country_mapping.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: product_type_most_common, Cardinality: 4682\n",
      "Column: product_gender_target_most_common, Cardinality: 2\n",
      "Column: product_category_most_common, Cardinality: 6\n",
      "Column: product_season_most_common, Cardinality: 3\n",
      "Column: product_condition_most_common, Cardinality: 5\n",
      "Column: brand_name_most_common, Cardinality: 5137\n",
      "Column: product_material_most_common, Cardinality: 68\n",
      "Column: product_color_most_common, Cardinality: 26\n",
      "Column: seller_badge, Cardinality: 3\n",
      "Column: warehouse_name_most_common, Cardinality: 6\n",
      "Column: usually_ships_within_most_common, Cardinality: 5\n",
      "Column: seller_country, Cardinality: 80\n"
     ]
    }
   ],
   "source": [
    "# Select categorical columns\n",
    "categorical_columns = X_train.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Calculate cardinality for each categorical column\n",
    "for col in categorical_columns:\n",
    "    unique_values = X_train[col].nunique()\n",
    "    print(f\"Column: {col}, Cardinality: {unique_values}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# large cardianlity affects training. too many features 11000 \n",
    "# using hybrid encoding: target encoding & one hot \n",
    "\n",
    "\n",
    "# HYBRID ENCODING\n",
    "\n",
    "# defining high and low cardinality features based on the suggested strategy\n",
    "high_cardinality_features = [\n",
    "    'product_type_most_common', 'brand_name_most_common',\n",
    "    'product_material_most_common', 'seller_country', 'product_color_most_common'\n",
    "]\n",
    "\n",
    "low_cardinality_features = [\n",
    "    'product_gender_target_most_common', 'product_category_most_common',\n",
    "    'product_season_most_common', 'product_condition_most_common' , 'seller_badge', \n",
    "    'warehouse_name_most_common', 'usually_ships_within_most_common'\n",
    "]\n",
    "\n",
    "# target encoding for high cardinality features\n",
    "for feature in high_cardinality_features:\n",
    "    # Calculate the mean of the target variable for each category\n",
    "    category_target_mean = X_train.groupby(feature)['seller_pass_rate'].mean()\n",
    "    \n",
    "    # Map the mean to both train and test sets\n",
    "    X_train[f\"{feature}_target_enc\"] = X_train[feature].map(category_target_mean)\n",
    "    X_test[f\"{feature}_target_enc\"] = X_test[feature].map(category_target_mean)\n",
    "    \n",
    "    # Drop the original high-cardinality feature\n",
    "    X_train.drop(columns=[feature], inplace=True)\n",
    "    X_test.drop(columns=[feature], inplace=True)\n",
    "\n",
    "# one-hot encoding for low-cardinality features\n",
    "X_train = pd.get_dummies(X_train, columns=low_cardinality_features, drop_first=True)\n",
    "X_test = pd.get_dummies(X_test, columns=low_cardinality_features, drop_first=True)\n",
    "\n",
    "# align columns of train and test to ensure they match after encoding\n",
    "X_train, X_test = X_train.align(X_test, join='left', axis=1, fill_value=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensuring target variable is dropped after encoding\n",
    "if target in X_train.columns:\n",
    "    X_train.drop(columns=[target], inplace=True)\n",
    "\n",
    "if target in X_test.columns:\n",
    "    X_test.drop(columns=[target], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape after target encoding: (113157, 61)\n",
      "X_test shape after target encoding: (28290, 61)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape after target encoding:\", X_train.shape)\n",
    "print(\"X_test shape after target encoding:\", X_test.shape)\n",
    "\n",
    "# before\n",
    "# print(\"X_train shape after target encoding:\", X_train.shape)\n",
    "#print(\"X_test shape after target encoding:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113157,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28290,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in X_train:\n",
      "Series([], dtype: int64)\n",
      "\n",
      "Missing values in y_train:\n",
      "seller_pass_rate    0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in X_test:\n",
      "product_type_most_common_target_enc    599\n",
      "brand_name_most_common_target_enc      522\n",
      "seller_country_target_enc                5\n",
      "dtype: int64\n",
      "\n",
      "Missing values in y_test:\n",
      "seller_pass_rate    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load your datasets\n",
    "X_train = pd.read_csv(\"X_train.csv\")\n",
    "y_train = pd.read_csv(\"y_train.csv\")\n",
    "X_test = pd.read_csv(\"X_test.csv\")\n",
    "y_test = pd.read_csv(\"y_test.csv\")\n",
    "\n",
    "# Check for missing values in each dataset\n",
    "print(\"Missing values in X_train:\")\n",
    "print(X_train.isnull().sum()[X_train.isnull().sum() > 0])\n",
    "\n",
    "print(\"\\nMissing values in y_train:\")\n",
    "print(y_train.isnull().sum())\n",
    "\n",
    "print(\"\\nMissing values in X_test:\")\n",
    "print(X_test.isnull().sum()[X_test.isnull().sum() > 0])\n",
    "\n",
    "print(\"\\nMissing values in y_test:\")\n",
    "print(y_test.isnull().sum())\n",
    "\n",
    "\n",
    "# missing values due to encoding. likely due to categories in xtest that didnt appear in xtrain so they didnt receive target encoded values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in X_test after filling:\n",
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# impute missing values in target-encoded columns in X_test using the mean from X_train\n",
    "for col in ['product_type_most_common_target_enc', 'brand_name_most_common_target_enc', 'seller_country_target_enc']:\n",
    "    mean_value = X_train[col].mean()  # Mean of the column in X_train\n",
    "    X_test[col].fillna(mean_value, inplace=True)\n",
    "\n",
    "# verifying that missing values are handled\n",
    "print(\"\\nMissing values in X_test after filling:\")\n",
    "print(X_test.isnull().sum()[X_test.isnull().sum() > 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# target-encoded training set (for class imbalance handling in separate notebooks)\n",
    "X_train.to_csv(\"X_train.csv\", index=False)\n",
    "y_train.to_csv(\"y_train.csv\", index=False)\n",
    "\n",
    "# separate test set (for consistent evaluation across all experiments)\n",
    "X_test.to_csv(\"X_test.csv\", index=False)\n",
    "y_test.to_csv(\"y_test.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
